{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_1329919/1125253963.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n",
      "/tmp/ipykernel_1329919/1125253963.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientnet_model.load_state_dict(torch.load('best_model_efficientnet_epoch_10_val_loss_0.4243_f1_0.9957.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 ./submission_ensemble_convnext_efficientnet.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from effdet import create_model\n",
    "from torchvision.models import convnext_tiny, efficientnet_b0, efficientnet_b3, efficientnet_b4\n",
    "\n",
    "# 사용자 데이터셋 정의 (테스트용)\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = pd.read_csv(labels_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋 및 DataLoader 설정\n",
    "test_dataset = CustomImageDataset(img_dir='../data_centric/test', labels_file='./sample_submission.csv', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 모델 로드 및 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ConvNeXt 모델 설정\n",
    "convnext_model = convnext_tiny(pretrained=False)\n",
    "convnext_model.classifier[2] = nn.Linear(convnext_model.classifier[2].in_features, 17)\n",
    "convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n",
    "convnext_model = convnext_model.to(device)\n",
    "convnext_model.eval()\n",
    "\n",
    "# EfficientNet 모델 설정\n",
    "efficientnet_model = efficientnet_b4(pretrained=False)\n",
    "\n",
    "# classifier의 마지막 레이어 크기 조정\n",
    "num_ftrs = efficientnet_model.classifier[1].in_features  # classifier의 두 번째 레이어가 Linear 레이어임\n",
    "efficientnet_model.classifier[1] = nn.Linear(num_ftrs, 17)  # 17개 클래스에 맞게 분류기 조정\n",
    "\n",
    "efficientnet_model.load_state_dict(torch.load('best_model_efficientnet_epoch_10_val_loss_0.4243_f1_0.9957.pth'))\n",
    "efficientnet_model = efficientnet_model.to(device)\n",
    "efficientnet_model.eval()\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측 수행\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # 각 모델로 예측 수행\n",
    "        convnext_outputs = convnext_model(images)\n",
    "        efficientnet_outputs = efficientnet_model(images)\n",
    "        # print(convnext_outputs)\n",
    "        # print(efficientnet_outputs)\n",
    "        # 예측 결과의 평균 앙상블 수행\n",
    "        outputs = (convnext_outputs + efficientnet_outputs) / 2\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 예측 결과를 DataFrame으로 저장\n",
    "submission_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "submission_df['target'] = all_predictions  # 예측 결과 할당\n",
    "\n",
    "submission_filename = f\"./submission_ensemble_convnext_efficientnet.csv\"\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 {submission_filename}로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_1329919/1734576123.py:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1329919/1734576123.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientnet_model.load_state_dict(torch.load(state_dict_path1, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 ./submission_ensemble_convnext_efficientnet_2.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision.models import convnext_tiny, efficientnet_b4\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# 사용자 데이터셋 정의 (테스트용)\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform_convnext=None, transform_efficientnet=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = pd.read_csv(labels_file)\n",
    "        self.transform_convnext = transform_convnext\n",
    "        self.transform_efficientnet = transform_efficientnet\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        image_convnext = self.transform_convnext(image) if self.transform_convnext else image\n",
    "        image_efficientnet = self.transform_efficientnet(image) if self.transform_efficientnet else image\n",
    "        \n",
    "        return image_convnext, image_efficientnet\n",
    "\n",
    "# ConvNeXt 데이터 전처리\n",
    "transform_convnext = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# EfficientNet 데이터 전처리\n",
    "transform_efficientnet = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋 및 DataLoader 설정\n",
    "test_dataset = CustomImageDataset(\n",
    "    img_dir='../data_centric/test', \n",
    "    labels_file='./sample_submission.csv', \n",
    "    transform_convnext=transform_convnext, \n",
    "    transform_efficientnet=transform_efficientnet\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 모델 로드 및 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ConvNeXt 모델 설정\n",
    "convnext_model = convnext_tiny(pretrained=False)\n",
    "convnext_model.classifier[2] = nn.Linear(convnext_model.classifier[2].in_features, 17)\n",
    "convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n",
    "convnext_model = convnext_model.to(device)\n",
    "convnext_model.eval()\n",
    "\n",
    "# # EfficientNet 모델 설정\n",
    "# efficientnet_model = efficientnet_b4(pretrained=False)\n",
    "# num_ftrs = efficientnet_model.classifier[1].in_features\n",
    "# efficientnet_model.classifier[1] = nn.Linear(num_ftrs, 17)\n",
    "# efficientnet_model.load_state_dict(torch.load('best_model_amber-sweep-1.pth'))\n",
    "# efficientnet_model = efficientnet_model.to(device)\n",
    "# efficientnet_model.eval()\n",
    "\n",
    "\n",
    "# EfficientNet 모델 설정\n",
    "efficientnet_model = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "efficientnet_model._fc = nn.Linear(efficientnet_model._fc.in_features, 17)\n",
    "state_dict_path1 = 'best_model_amber-sweep-1.pth'\n",
    "efficientnet_model.load_state_dict(torch.load(state_dict_path1, map_location=device))\n",
    "efficientnet_model = efficientnet_model.to(device)\n",
    "efficientnet_model.eval()\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측 수행\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for images_convnext, images_efficientnet in test_loader:\n",
    "        images_convnext = images_convnext.to(device)\n",
    "        images_efficientnet = images_efficientnet.to(device)\n",
    "        \n",
    "        # 각 모델로 예측 수행\n",
    "        convnext_outputs = convnext_model(images_convnext)\n",
    "        efficientnet_outputs = efficientnet_model(images_efficientnet)\n",
    "        \n",
    "        # 예측 결과의 평균 앙상블 수행\n",
    "        outputs = (convnext_outputs + efficientnet_outputs) / 2\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 예측 결과를 DataFrame으로 저장\n",
    "submission_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "submission_df['target'] = all_predictions  # 예측 결과 할당\n",
    "\n",
    "submission_filename = f\"./submission_ensemble_convnext_efficientnet_2.csv\"\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 {submission_filename}로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /data/ephemeral/home/tf/lib/python3.10/site-packages (from efficientnet_pytorch) (2.5.1)\n",
      "Requirement already satisfied: filelock in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/ephemeral/home/tf/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
      "Building wheels for collected packages: efficientnet_pytorch\n",
      "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=ca5085777309eae37132172c83a02c2b9c0bd6d08e4693a4d969b679bfb941ac\n",
      "  Stored in directory: /data/ephemeral/home/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
      "Successfully built efficientnet_pytorch\n",
      "Installing collected packages: efficientnet_pytorch\n",
      "Successfully installed efficientnet_pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_1329919/4069942408.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1329919/4069942408.py:145: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientnet_model.load_state_dict(torch.load('best_model_amber-sweep-1.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1329919/4069942408.py:152: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientnet_model2.load_state_dict(torch.load('best_model_new_2~3_model.pth'))\n",
      "/tmp/ipykernel_1329919/4069942408.py:159: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientdet_model.load_state_dict(torch.load(latest_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 ./submission_ensemble_convnext_efficientnet_efficientdet_efficientnet.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import f1_score\n",
    "from effdet import create_model\n",
    "from torchvision.models import convnext_tiny\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Focal Loss 정의\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        log_prob = nn.functional.log_softmax(inputs, dim=1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        target_log_prob = log_prob.gather(1, targets.view(-1, 1)).squeeze(1)\n",
    "        target_prob = prob.gather(1, targets.view(-1, 1)).squeeze(1)\n",
    "        \n",
    "        focal_term = (1 - target_prob) ** self.gamma\n",
    "        loss = -self.alpha * focal_term * target_log_prob\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "# EfficientDet 기반 분류 모델 정의\n",
    "class EfficientDetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientDetClassifier, self).__init__()\n",
    "        self.model = create_model(\n",
    "            'tf_efficientdet_d0',\n",
    "            bench_task='train',\n",
    "            num_classes=num_classes,\n",
    "            pretrained=True\n",
    "        )\n",
    "        \n",
    "        # 백본 고정\n",
    "        self.backbone = self.model.model.backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # BiFPN 설정 및 출력 크기 추론\n",
    "        self.bifpn = self.model.model.fpn\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # 임의의 입력으로 BiFPN 출력 피처 크기 추론\n",
    "        dummy_input = torch.randn(1, 3, 512, 512)\n",
    "        with torch.no_grad():\n",
    "            features = self.bifpn(self.backbone(dummy_input))\n",
    "        num_features = features[-1].shape[1]\n",
    "        \n",
    "        # 새로운 분류기 레이어\n",
    "        self.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.bifpn(x)[-1]  # 마지막 BiFPN 레이어의 출력 사용\n",
    "        x = self.pool(x).flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 사용자 데이터셋 정의 (테스트용)\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform_convnext=None, transform_efficientnet=None, transform_efficientnet2=None, transform_efficientdet=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = pd.read_csv(labels_file)\n",
    "        self.transform_convnext = transform_convnext\n",
    "        self.transform_efficientnet = transform_efficientnet\n",
    "        self.transform_efficientnet2 = transform_efficientnet2\n",
    "        self.transform_efficientdet = transform_efficientdet\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        image_convnext = self.transform_convnext(image) if self.transform_convnext else image\n",
    "        image_efficientnet = self.transform_efficientnet(image) if self.transform_efficientnet else image\n",
    "        image_efficientnet2 = self.transform_efficientnet2(image) if self.transform_efficientnet2 else image\n",
    "        image_efficientdet = self.transform_efficientdet(image) if self.transform_efficientdet else image\n",
    "        \n",
    "        return image_convnext, image_efficientnet, image_efficientnet2, image_efficientdet\n",
    "\n",
    "# ConvNeXt 데이터 전처리\n",
    "transform_convnext = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# EfficientNet 데이터 전처리\n",
    "transform_efficientnet = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# EfficientNet2 데이터 전처리\n",
    "transform_efficientnet2 = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# EfficientDet 데이터 전처리\n",
    "transform_efficientdet = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋 및 DataLoader 설정\n",
    "test_dataset = CustomImageDataset(\n",
    "    img_dir='../data_centric/test', \n",
    "    labels_file='./sample_submission.csv', \n",
    "    transform_convnext=transform_convnext, \n",
    "    transform_efficientnet=transform_efficientnet,\n",
    "    transform_efficientnet2=transform_efficientnet2, \n",
    "    transform_efficientdet=transform_efficientdet\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 모델 로드 및 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ConvNeXt 모델 설정\n",
    "convnext_model = convnext_tiny(pretrained=False)\n",
    "convnext_model.classifier[2] = nn.Linear(convnext_model.classifier[2].in_features, 17)\n",
    "convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n",
    "convnext_model = convnext_model.to(device)\n",
    "convnext_model.eval()\n",
    "\n",
    "# EfficientNet 모델 설정\n",
    "efficientnet_model = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "efficientnet_model._fc = nn.Linear(efficientnet_model._fc.in_features, 17)\n",
    "efficientnet_model.load_state_dict(torch.load('best_model_amber-sweep-1.pth'))\n",
    "efficientnet_model = efficientnet_model.to(device)\n",
    "efficientnet_model.eval()\n",
    "\n",
    "# EfficientNet2 모델 설정\n",
    "efficientnet_model2 = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "efficientnet_model2._fc = nn.Linear(efficientnet_model2._fc.in_features, 17)\n",
    "efficientnet_model2.load_state_dict(torch.load('best_model_new_2~3_model.pth'))\n",
    "efficientnet_model2 = efficientnet_model2.to(device)\n",
    "efficientnet_model2.eval()\n",
    "\n",
    "# EfficientDet 모델 설정\n",
    "efficientdet_model = EfficientDetClassifier(num_classes=17)\n",
    "latest_model_path = './best_model_efficientdet_epoch_30_val_loss_0.0448_f1_0.9644.pth'\n",
    "efficientdet_model.load_state_dict(torch.load(latest_model_path))\n",
    "efficientdet_model = efficientdet_model.to(device)\n",
    "efficientdet_model.eval()\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측 수행\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for images_convnext, images_efficientnet, images_efficientnet2, images_efficientdet in test_loader:\n",
    "        images_convnext = images_convnext.to(device)\n",
    "        images_efficientnet = images_efficientnet.to(device)\n",
    "        images_efficientnet2 = images_efficientnet2.to(device)\n",
    "        images_efficientdet = images_efficientdet.to(device)\n",
    "        \n",
    "        # 각 모델로 예측 수행\n",
    "        convnext_outputs = convnext_model(images_convnext)\n",
    "        efficientnet_outputs = efficientnet_model(images_efficientnet)\n",
    "        efficientnet_outputs2 = efficientnet_model2(images_efficientnet2)\n",
    "        efficientdet_outputs = efficientdet_model(images_efficientdet)\n",
    "        \n",
    "        # 예측 결과의 평균 앙상블 수행\n",
    "        outputs = (convnext_outputs + efficientnet_outputs + efficientnet_outputs2 + efficientdet_outputs) / 4\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 예측 결과를 DataFrame으로 저장\n",
    "submission_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "submission_df['target'] = all_predictions  # 예측 결과 할당\n",
    "\n",
    "submission_filename = \"./submission_ensemble_convnext_efficientnet_efficientdet_efficientnet.csv\"\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 {submission_filename}로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_1329919/623635141.py:148: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1329919/623635141.py:155: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientnet_model.load_state_dict(torch.load('best_model_amber-sweep-1.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1329919/623635141.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientnet_model2.load_state_dict(torch.load('best_model_new_2~3_model.pth'))\n",
      "/tmp/ipykernel_1329919/623635141.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  efficientdet_model.load_state_dict(torch.load(latest_model_path))\n",
      "/tmp/ipykernel_1329919/623635141.py:176: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_model.load_state_dict(torch.load('best_resnet50_epoch_6_loss_0.4323_f1_0.9948_acc_0.9949_prec_0.9949_rec_0.9948.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 ./submission_ensemble_convnext_efficientnet_efficientdet_resnet.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import f1_score\n",
    "from effdet import create_model\n",
    "from torchvision.models import convnext_tiny, resnet50\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Focal Loss 정의\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        log_prob = nn.functional.log_softmax(inputs, dim=1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        target_log_prob = log_prob.gather(1, targets.view(-1, 1)).squeeze(1)\n",
    "        target_prob = prob.gather(1, targets.view(-1, 1)).squeeze(1)\n",
    "        \n",
    "        focal_term = (1 - target_prob) ** self.gamma\n",
    "        loss = -self.alpha * focal_term * target_log_prob\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "# EfficientDet 기반 분류 모델 정의\n",
    "class EfficientDetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientDetClassifier, self).__init__()\n",
    "        self.model = create_model(\n",
    "            'tf_efficientdet_d0',\n",
    "            bench_task='train',\n",
    "            num_classes=num_classes,\n",
    "            pretrained=True\n",
    "        )\n",
    "        \n",
    "        # 백본 고정\n",
    "        self.backbone = self.model.model.backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # BiFPN 설정 및 출력 크기 추론\n",
    "        self.bifpn = self.model.model.fpn\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # 임의의 입력으로 BiFPN 출력 피처 크기 추론\n",
    "        dummy_input = torch.randn(1, 3, 512, 512)\n",
    "        with torch.no_grad():\n",
    "            features = self.bifpn(self.backbone(dummy_input))\n",
    "        num_features = features[-1].shape[1]\n",
    "        \n",
    "        # 새로운 분류기 레이어\n",
    "        self.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.bifpn(x)[-1]  # 마지막 BiFPN 레이어의 출력 사용\n",
    "        x = self.pool(x).flatten(1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 사용자 데이터셋 정의 (테스트용)\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform_convnext=None, transform_efficientnet=None, transform_efficientnet2=None, transform_efficientdet=None, transform_resnet=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.df = pd.read_csv(labels_file)\n",
    "        self.transform_convnext = transform_convnext\n",
    "        self.transform_efficientnet = transform_efficientnet\n",
    "        self.transform_efficientnet2 = transform_efficientnet2\n",
    "        self.transform_efficientdet = transform_efficientdet\n",
    "        self.transform_resnet = transform_resnet\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        image_convnext = self.transform_convnext(image) if self.transform_convnext else image\n",
    "        image_efficientnet = self.transform_efficientnet(image) if self.transform_efficientnet else image\n",
    "        image_efficientnet2 = self.transform_efficientnet2(image) if self.transform_efficientnet2 else image\n",
    "        image_efficientdet = self.transform_efficientdet(image) if self.transform_efficientdet else image\n",
    "        image_resnet = self.transform_resnet(image) if self.transform_resnet else image\n",
    "        \n",
    "        return image_convnext, image_efficientnet, image_efficientnet2, image_efficientdet, image_resnet\n",
    "\n",
    "# ConvNeXt 데이터 전처리\n",
    "transform_convnext = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# EfficientNet 데이터 전처리\n",
    "transform_efficientnet = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# EfficientNet2 데이터 전처리\n",
    "transform_efficientnet2 = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# EfficientDet 데이터 전처리\n",
    "transform_efficientdet = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# ResNet50 데이터 전처리\n",
    "transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋 및 DataLoader 설정\n",
    "test_dataset = CustomImageDataset(\n",
    "    img_dir='../data_centric/test', \n",
    "    labels_file='./sample_submission.csv', \n",
    "    transform_convnext=transform_convnext, \n",
    "    transform_efficientnet=transform_efficientnet,\n",
    "    transform_efficientnet2=transform_efficientnet2, \n",
    "    transform_efficientdet=transform_efficientdet,\n",
    "    transform_resnet=transform_resnet\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 모델 로드 및 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ConvNeXt 모델 설정\n",
    "convnext_model = convnext_tiny(pretrained=False)\n",
    "convnext_model.classifier[2] = nn.Linear(convnext_model.classifier[2].in_features, 17)\n",
    "convnext_model.load_state_dict(torch.load('best_model_convnext_epoch_10_val_loss_0.4171_f1_0.9971.pth'))\n",
    "convnext_model = convnext_model.to(device)\n",
    "convnext_model.eval()\n",
    "\n",
    "# EfficientNet 모델 설정\n",
    "efficientnet_model = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "efficientnet_model._fc = nn.Linear(efficientnet_model._fc.in_features, 17)\n",
    "efficientnet_model.load_state_dict(torch.load('best_model_amber-sweep-1.pth'))\n",
    "efficientnet_model = efficientnet_model.to(device)\n",
    "efficientnet_model.eval()\n",
    "\n",
    "# EfficientNet2 모델 설정\n",
    "efficientnet_model2 = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "efficientnet_model2._fc = nn.Linear(efficientnet_model2._fc.in_features, 17)\n",
    "efficientnet_model2.load_state_dict(torch.load('best_model_new_2~3_model.pth'))\n",
    "efficientnet_model2 = efficientnet_model2.to(device)\n",
    "efficientnet_model2.eval()\n",
    "\n",
    "# EfficientDet 모델 설정\n",
    "efficientdet_model = EfficientDetClassifier(num_classes=17)\n",
    "latest_model_path = './best_model_efficientdet_epoch_30_val_loss_0.0448_f1_0.9644.pth'\n",
    "efficientdet_model.load_state_dict(torch.load(latest_model_path))\n",
    "efficientdet_model = efficientdet_model.to(device)\n",
    "efficientdet_model.eval()\n",
    "\n",
    "# ResNet50 모델 설정\n",
    "resnet_model = resnet50(pretrained=False)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 17)\n",
    "resnet_model.load_state_dict(torch.load('best_resnet50_epoch_6_loss_0.4323_f1_0.9948_acc_0.9949_prec_0.9949_rec_0.9948.pth'))\n",
    "resnet_model = resnet_model.to(device)\n",
    "resnet_model.eval()\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측 수행\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for images_convnext, images_efficientnet, images_efficientnet2, images_efficientdet, images_resnet in test_loader:\n",
    "        images_convnext = images_convnext.to(device)\n",
    "        images_efficientnet = images_efficientnet.to(device)\n",
    "        images_efficientnet2 = images_efficientnet2.to(device)\n",
    "        images_efficientdet = images_efficientdet.to(device)\n",
    "        images_resnet = images_resnet.to(device)\n",
    "        \n",
    "        # 각 모델로 예측 수행\n",
    "        convnext_outputs = convnext_model(images_convnext)\n",
    "        efficientnet_outputs = efficientnet_model(images_efficientnet)\n",
    "        efficientnet_outputs2 = efficientnet_model2(images_efficientnet2)\n",
    "        efficientdet_outputs = efficientdet_model(images_efficientdet)\n",
    "        resnet_outputs = resnet_model(images_resnet)\n",
    "        \n",
    "        # 예측 결과의 평균 앙상블 수행\n",
    "        outputs = (convnext_outputs + efficientnet_outputs + efficientnet_outputs2 + efficientdet_outputs + resnet_outputs) / 5\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 예측 결과를 DataFrame으로 저장\n",
    "submission_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "submission_df['target'] = all_predictions  # 예측 결과 할당\n",
    "\n",
    "submission_filename = \"./submission_ensemble_convnext_efficientnet_efficientdet_resnet.csv\"\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"테스트 데이터에 대한 앙상블 예측이 완료되었습니다. 파일이 {submission_filename}로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
