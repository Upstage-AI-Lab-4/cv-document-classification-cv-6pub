{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import albumentations as at\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 경로 설정\n",
    "input_folder = '/root/data/home/data/train'\n",
    "output_folder = '/root/data/home/data/V6_train'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "train_csv_path = '/root/data/home/data/train.csv'\n",
    "output_csv_path = '/root/data/home/data/V6_train_labels.csv'\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(train_csv_path)\n",
    "label_dict = dict(zip(df['ID'], df['target']))\n",
    "\n",
    "# 변환 파이프라인 정의\n",
    "augmentation_pipeline = at.Compose([\n",
    "    at.SomeOf([\n",
    "        at.GaussNoise(p=1, var_limit=(500, 1000)),\n",
    "        at.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.3, 0.3), p=1),\n",
    "        at.HorizontalFlip(p=1),\n",
    "        at.VerticalFlip(p=1),\n",
    "    ], n=random.randint(2, 3), p=1),\n",
    "    at.SomeOf([\n",
    "        at.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=1),  # Cutout\n",
    "        at.GridDistortion(num_steps=5, distort_limit=0.3, p=1),  # Grid Distortion\n",
    "        at.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1),  # Elastic Transform\n",
    "        at.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=1),  # Random Shift, Scale, Rotate\n",
    "        at.CLAHE(clip_limit=2, p=1),  # CLAHE for Contrast Limited Adaptive Histogram Equalization\n",
    "        at.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1),  # Hue Saturation\n",
    "        at.MultiplicativeNoise(multiplier=(0.5, 1.5), p=0.5),  # Multiplicative Noise for color variation\n",
    "    ], n=random.randint(1, 2), p=1),\n",
    "    #정방형으로 돌아가기 때문에, 10도씩 여백을 줌\n",
    "    at.OneOf([\n",
    "        at.Rotate(limit=(10, 30), border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),\n",
    "        at.Rotate(limit=(150, 170), border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),\n",
    "        at.Rotate(limit=(190, 210), border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),\n",
    "        at.Rotate(limit=(330, 350), border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),\n",
    "    ], p=1),\n",
    "])\n",
    "# MixUp 함수 정의 (랜덤하게 적용)\n",
    "def mixup(image_path, label, labels_df, alpha=0.5, apply_prob=0.5):\n",
    "    if np.random.rand() > apply_prob:\n",
    "        return cv2.imread(image_path)\n",
    "    \n",
    "    same_class_images = labels_df[labels_df['target'] == label]['ID'].tolist()\n",
    "    image_name = os.path.basename(image_path)\n",
    "    if image_name in same_class_images:\n",
    "        same_class_images.remove(image_name)\n",
    "    \n",
    "    if same_class_images:\n",
    "        random_image_name = random.choice(same_class_images)\n",
    "        random_image_path = os.path.join(input_folder, random_image_name)\n",
    "        \n",
    "        image1 = cv2.imread(image_path)\n",
    "        image2 = cv2.imread(random_image_path)\n",
    "        if image1 is not None and image2 is not None:\n",
    "            image2_resized = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
    "            mixed_image = cv2.addWeighted(image1, alpha, image2_resized, 1 - alpha, 0)\n",
    "            return mixed_image\n",
    "    return cv2.imread(image_path)\n",
    "\n",
    "# 이미지 증강 및 저장 함수\n",
    "output_data = []\n",
    "def augment_and_save(image_path, output_folder, augmentations, label, labels_df, num_augments=60):\n",
    "    filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"이미지 로드 실패: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # 원본 이미지 저장\n",
    "    original_output_path = os.path.join(output_folder, f\"{filename}_origin.jpg\")\n",
    "    cv2.imwrite(original_output_path, image)\n",
    "    output_data.append([f\"{filename}_origin.jpg\", label])\n",
    "    \n",
    "    # MixUp 및 증강 이미지 저장\n",
    "    for i in range(num_augments):\n",
    "        mixed_image = mixup(image_path, label, labels_df, apply_prob=0.2)\n",
    "        \n",
    "        # 증강 처리\n",
    "        augmented_image = augmentations(image=mixed_image)['image']\n",
    "        \n",
    "        # 파일명 형식 변경\n",
    "        if np.array_equal(mixed_image, image):\n",
    "            augment_type = \"original\"  # MixUp이 적용되지 않은 경우\n",
    "        else:\n",
    "            augment_type = \"mixup\"\n",
    "        \n",
    "        output_path = os.path.join(output_folder, f\"{filename}_{augment_type}_aug_{i+1}.jpg\")\n",
    "        cv2.imwrite(output_path, augmented_image)\n",
    "        output_data.append([f\"{filename}_{augment_type}_aug_{i+1}.jpg\", label])\n",
    "\n",
    "# 모든 이미지에 대해 증강 및 저장\n",
    "for img_file in os.listdir(input_folder):\n",
    "    img_path = os.path.join(input_folder, img_file)\n",
    "    label = label_dict.get(img_file)\n",
    "    if label is not None:\n",
    "        augment_and_save(img_path, output_folder, augmentation_pipeline, label, df)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "output_df = pd.DataFrame(output_data, columns=['ID', 'target'])\n",
    "output_df.to_csv(output_csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V7 데이터셋이 /root/data/home/data/V7_train에 생성되었고, 라벨 CSV 파일이 /root/data/home/data/V7_train_labels.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# 경로 설정\n",
    "v1_folder = '/root/data/home/data/prcd_train'\n",
    "v2_folder = '/root/data/home/data/V2_train'\n",
    "v6_folder = '/root/data/home/data/V6_train'\n",
    "v7_folder = '/root/data/home/data/V7_train'\n",
    "v7_csv_path = '/root/data/home/data/V7_train_labels.csv'\n",
    "\n",
    "# V7 디렉토리 생성\n",
    "os.makedirs(v7_folder, exist_ok=True)\n",
    "\n",
    "# V1, V2, V6의 파일을 V7로 복사하고 라벨 정보 수집\n",
    "label_data = []\n",
    "\n",
    "# V1 폴더의 파일 복사 및 라벨 수집\n",
    "v1_labels = pd.read_csv('/root/data/home/data/prcd_train_labels.csv')\n",
    "for _, row in v1_labels.iterrows():\n",
    "    src_path = os.path.join(v1_folder, row['ID'])\n",
    "    dst_path = os.path.join(v7_folder, row['ID'])\n",
    "    shutil.copy(src_path, dst_path)\n",
    "    label_data.append([row['ID'], row['target']])\n",
    "\n",
    "# V2 폴더의 파일 복사 및 라벨 수집\n",
    "v2_labels = pd.read_csv('/root/data/home/data/V2_train_labels.csv')\n",
    "for _, row in v2_labels.iterrows():\n",
    "    src_path = os.path.join(v2_folder, row['ID'])\n",
    "    dst_path = os.path.join(v7_folder, row['ID'])\n",
    "    shutil.copy(src_path, dst_path)\n",
    "    label_data.append([row['ID'], row['target']])\n",
    "\n",
    "# V6 폴더의 파일 복사 및 라벨 수집\n",
    "v6_labels = pd.read_csv('/root/data/home/data/V6_train_labels.csv')\n",
    "for _, row in v6_labels.iterrows():\n",
    "    src_path = os.path.join(v6_folder, row['ID'])\n",
    "    dst_path = os.path.join(v7_folder, row['ID'])\n",
    "    shutil.copy(src_path, dst_path)\n",
    "    label_data.append([row['ID'], row['target']])\n",
    "\n",
    "# 라벨 정보를 데이터프레임으로 변환하고 CSV로 저장\n",
    "v7_labels_df = pd.DataFrame(label_data, columns=['ID', 'target'])\n",
    "v7_labels_df.to_csv(v7_csv_path, index=False)\n",
    "\n",
    "print(f\"V7 데이터셋이 {v7_folder}에 생성되었고, 라벨 CSV 파일이 {v7_csv_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_pipeline = at.Compose([\n",
    "    at.SomeOf([\n",
    "        at.GaussNoise(p=1, var_limit=(500, 1000)),\n",
    "        at.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit=(-0.3, 0.3), p=1),\n",
    "        at.HorizontalFlip(p=1),\n",
    "        at.VerticalFlip(p=1),\n",
    "    ], n=random.randint(2, 3), p=1),\n",
    "    at.SomeOf([\n",
    "        at.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=1),  # Cutout\n",
    "        at.GridDistortion(num_steps=5, distort_limit=0.3, p=1),  # Grid Distortion\n",
    "        at.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1),  # Elastic Transform\n",
    "        at.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=1),  # Random Shift, Scale, Rotate\n",
    "        at.CLAHE(clip_limit=2, p=1),  # CLAHE for Contrast Limited Adaptive Histogram Equalization\n",
    "        at.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1),  # Hue Saturation\n",
    "        at.MultiplicativeNoise(multiplier=(0.5, 1.5), p=0.5),  # Multiplicative Noise for color variation\n",
    "    ], n=random.randint(1, 2), p=1),\n",
    "    at.Rotate(limit=(-180, 180), border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
